Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job stats:
job             count    min threads    max threads
------------  -------  -------------  -------------
all                 1              1              1
make_archive        1              1              1
make_plot           1              1              1
zipf_test           1              1              1
total               4              1              1

Select jobs to execute...

[Tue Mar 29 10:54:14 2022]
rule make_plot:
    input: source/plotcount.py, processed_data/sierra.dat
    output: results/sierra.png
    jobid: 2
    wildcards: file=sierra
    resources: tmpdir=/tmp

[Tue Mar 29 10:54:16 2022]
Finished job 2.
1 of 4 steps (25%) done
Select jobs to execute...

[Tue Mar 29 10:54:16 2022]
rule zipf_test:
    input: source/zipf_test.py, processed_data/sierra.dat, processed_data/last.dat, processed_data/abyss.dat, processed_data/isles.dat
    output: results/results.txt
    jobid: 10
    resources: tmpdir=/tmp

[Tue Mar 29 10:54:16 2022]
Finished job 10.
2 of 4 steps (50%) done
Select jobs to execute...

[Tue Mar 29 10:54:16 2022]
localrule make_archive:
    input: results/sierra.png, results/last.png, results/abyss.png, results/isles.png, processed_data/sierra.dat, processed_data/last.dat, processed_data/abyss.dat, processed_data/isles.dat, results/results.txt
    output: zipf_analysis.tar.gz
    jobid: 1
    resources: tmpdir=/tmp

[Tue Mar 29 10:54:17 2022]
Finished job 1.
3 of 4 steps (75%) done
Select jobs to execute...

[Tue Mar 29 10:54:17 2022]
localrule all:
    input: zipf_analysis.tar.gz
    jobid: 0
    resources: tmpdir=/tmp

[Tue Mar 29 10:54:17 2022]
Finished job 0.
4 of 4 steps (100%) done
Complete log: /home/lke/Dropbox/Course/CodeRefinery/word_count/.snakemake/log/2022-03-29T105414.669766.snakemake.log
